# -*- coding: utf-8 -*-
"""IMAGE_colourization_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14IfXGfCjGMCmJ7daH1wAE64qQY_xN5PJ
"""

#importing all necessary libraries
import pandas as pd
import numpy as np
import os
import cv2
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import load_model
from keras import models,layers
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
from sklearn.preprocessing import LabelEncoder

from google.colab import drive
drive.mount('/content/drive')

# giving path to the google drive folder
folder_path = '/content/drive/MyDrive/iml_files'

# Listing all files in the folder
files = os.listdir(folder_path)
print("Files in folder:", files)

file_name = 'gray_scale.npy'
file_path = os.path.join(folder_path, file_name)
l_images = np.load(file_path, allow_pickle=True)

file_name = 'ab1.npy'
file_path = os.path.join(folder_path, file_name)
ab1_images = np.load(file_path, allow_pickle=True)

file_name = 'ab2.npy'
file_path = os.path.join(folder_path, file_name)
ab2_images = np.load(file_path, allow_pickle=True)

file_name = 'ab3.npy'
file_path = os.path.join(folder_path, file_name)
ab3_images = np.load(file_path, allow_pickle=True)

#checking shapes of the loaded numpy files
print(ab1_images.shape)
print(ab2_images.shape)
print(ab3_images.shape)
print(l_images.shape)

# Checking if GPU is available
if tf.config.list_physical_devices('GPU'):
    with tf.device('/GPU:0'):
        # Move l and ab to GPU and normalize
        l_images = tf.constant(l_images, dtype=tf.float32) / 255.0  # Normalize to [0, 1]
        ab_train = tf.concat([ab1_images, ab2_images], axis=0) / 128.0 - 1  # Normalize to [-1, 1]
        ab_test = ab3_images / 128.0 - 1  # Normalize to [-1, 1]
else:
    # If no GPU, using CPU
    l_images = l_images / 255.0
    ab_train = np.concatenate((ab1_images, ab2_images), axis=0) / 128.0 - 1
    ab_test = ab3_images / 128.0 - 1

from sklearn.model_selection import train_test_split
L_train,L_test=train_test_split(l_images,test_size=0.2,random_state=42) #20% test set will be best acc to the number of images available in l_images.

# Function to resize both input and target images
def resize_images(l, ab):
    # Reshape of l and ab to (height, width, channels)
    l = tf.expand_dims(l, axis=-1)  # Adding a channel dimension if necessary for grayscale images
    l_resized = tf.image.resize(l, [128, 128])

    ab_resized = tf.image.resize(ab, [128, 128])
    return l_resized, ab_resized

# Convert to tf.data.Dataset and apply resizing
train_dataset = tf.data.Dataset.from_tensor_slices((L_train, ab_train))
train_dataset = train_dataset.map(resize_images).batch(32).prefetch(tf.data.AUTOTUNE) #using batch size=32

test_dataset = tf.data.Dataset.from_tensor_slices((L_test, ab_test))
test_dataset = test_dataset.map(resize_images).batch(32).prefetch(tf.data.AUTOTUNE)   #using batch size=32

from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2 # Importing the InceptionResNetV2 model
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Conv2D, UpSampling2D

def inception_resnet():
    # Loading the pre-trained InceptionResNetV2 model, excluding the top layers for more accurate results
    base_model = InceptionResNetV2(weights=None, include_top=False, input_shape=(128, 128, 1))  #only 1 channel for grayscale input

    weights_path = '/content/drive/MyDrive/iml_files/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5'
    base_model.load_weights(weights_path, by_name=True, skip_mismatch=True)  #skipping unmatched weights for consistency

    # Adding layers for upsampling and predicting ab channels
    x = base_model.output
    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)  #1st hidden layer with 256 filters
    x = UpSampling2D((2, 2))(x)
    x = Conv2D(196, (3, 3), activation='relu', padding='same')(x)  #2nd hidden layer with 196 filters
    x = UpSampling2D((2, 2))(x)
    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)   #3rd hidden layer with 64 filters
    x = UpSampling2D((2, 2))(x)
    x = Conv2D(2, (3, 3), activation='tanh', padding='same')(x)  #output layer with 2 channels(2 feature maps) for a & b
    x = tf.image.resize(x, (128, 128))  # Resizing output to 128x128

    # Scaling the output to match the LAB color space/consistent
    output_ab = x * 128

    model = Model(inputs=base_model.input, outputs=x)
    return model

#model = inception_resnet()  # Your model definition
#from tensorflow.keras.optimizers import Adam
#model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')

from tensorflow.keras.models import load_model  #for loading the saved weights till last epoch completed

# Loading the saved model from epoch 15
model = load_model('/content/drive/MyDrive/iml_files/colorization_model_epoch_15.h5')

from tensorflow.keras.callbacks import ModelCheckpoint

checkpoint_callback = ModelCheckpoint(
    filepath='/content/drive/MyDrive/iml_files/colorization_model_epoch_{epoch:02d}.h5',
    save_weights_only=False,            # Save the entire model
    save_best_only=False,               # Save every time regardless of improvement
    save_freq=1500   # for saving the model after every 2.5 epochs(roughly), here 1500 refers to batches completed
)

# Training the model
epochs = 15
batch_size = 32  #for maintaining consistency

# Fitting the model
history = model.fit(
    train_dataset,
    validation_data=test_dataset,
    epochs=epochs,
     initial_epoch=15,  #since we trained till 15 epochs
    steps_per_epoch=len(L_train) // batch_size,
    validation_steps=len(L_test) // batch_size,
    callbacks=[checkpoint_callback]    # Adding the checkpoint callback
)

# Recompiling the model
model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])

# Evaluating on the test dataset
test_loss, test_accuracy = model.evaluate(test_dataset)
print(f'Test Loss: {test_loss}')
print(f'Test Accuracy: {test_accuracy}')

# making predictions
predictions = model.predict(test_dataset)

def lab_to_rgb(l_channel, ab_channels):
    # Reshape the L channel to add an extra dimension
    l_channel = np.expand_dims(l_channel, axis=-1) * 100  # Scale L channel
    ab_channels = ab_channels * 128  # Scale ab channels

    # Concatenate L and ab channels to get a LAB image
    lab_image = np.concatenate((l_channel, ab_channels), axis=-1)
    lab_image = lab_image.astype(np.float32)

    # Convert LAB to RGB
    rgb_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2RGB)
    return rgb_image

# Plotting the real label, grayscale image, and colorized image side by side for better visualization
for l_channel, ab_channel in test_dataset.take(5):  # Taking a few examples
    # Predicting ab channels
    predicted_ab = model.predict(l_channel)

    # Converting grayscale image to RGB using the real and predicted ab channels
    l_channel_np = l_channel[0].numpy().squeeze()  # Extract and reshape for grayscale
    real_ab = ab_channel[0].numpy()  # Ground truth ab channels
    predicted_ab = predicted_ab[0]  # Predicted ab channels

#[0] selects the first image from the batch.
#.numpy() converts the TensorFlow tensor to a NumPy array.
#.squeeze() reshapes the array by removing any singleton dimensions for easier visualization.

    # Convert real and predicted LAB to RGB
    colorized_img = lab_to_rgb(l_channel_np, predicted_ab)
    real_img = lab_to_rgb(l_channel_np, real_ab)

    # Plot the grayscale, colorized, and real images
    plt.figure(figsize=(18, 6))
    plt.subplot(1, 3, 1)
    plt.imshow(l_channel_np, cmap='gray')
    plt.title("Grayscale Image (L)")

    plt.subplot(1, 3, 2)
    plt.imshow(colorized_img)
    plt.title("Colorized Image (Predicted)")

    plt.subplot(1, 3, 3)
    plt.imshow(real_img)
    plt.title("Real Color Image (Ground Truth)")

    plt.show()

# Define epochs and corresponding loss values
epochs = list(range(1, 16))  # Epochs 1 to 15
train_loss = [0.0359] + [0.0162] * 14  # First epoch loss followed by the same loss for remaining epochs as obtained from training the model

# validation losses (mix of 0.0191 and 0.0192)
val_loss = [0.0191, 0.0192, 0.0191, 0.0192, 0.0192,
            0.0191, 0.0192, 0.0191, 0.0192, 0.0192,
            0.0191, 0.0192, 0.0191, 0.0192, 0.0191]  # Adjusted for each epoch

# Plotting the loss
plt.figure(figsize=(10, 6))
plt.plot(epochs, train_loss, label='Training Loss', marker='o')
plt.plot(epochs, val_loss, label='Validation Loss', marker='o')
plt.title('Training and Validation Loss over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.xticks(epochs)  # All epochs on the x-axis
plt.grid()
plt.legend()
plt.show()

epochs = 15
epochs_range = range(epochs)


# Plotting Test Loss and Accuracy
plt.subplot(1, 2, 2)
plt.plot(epochs_range, [test_loss] * len(epochs_range), 'r--', label='Test Loss')
plt.plot(epochs_range, history.history.get('accuracy', [None]*len(epochs_range)))
plt.plot(epochs_range, history.history.get('val_accuracy', [None]*len(epochs_range)))
plt.xlabel('Epochs')
plt.ylabel('Accuracy / Loss')
plt.title('Epochs vs. Test Loss & Accuracy')
plt.legend()

plt.tight_layout()
plt.show()